import streamlit as st
import pandas as pd
import numpy as np

# =========================================
# 0. ê¸°ë³¸ ì„¤ì •
# =========================================
st.set_page_config(
    page_title="HR ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ",
    layout="wide"
)

st.title("ğŸ‘¥ HR ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ")

# =========================================
# 1. ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# =========================================
@st.cache_data
def load_data():
    # ê°™ì€ í´ë”ì˜ company_hr_data.xlsx ì½ê¸°
    xls = pd.ExcelFile("company_hr_data.xlsx")
    df_change = pd.read_excel(xls, "ì¸ì›ë³€ë™")
    df_turnover = pd.read_excel(xls, "í‡´ì‚¬ìœ¨")
    df_retention = pd.read_excel(xls, "ì”ì¡´ìœ¨")
    df_tenure = pd.read_excel(xls, "ê·¼ì†")
    return df_change, df_turnover, df_retention, df_tenure

# =========================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# =========================================
def to_month_period(series):
    """ì›” ì»¬ëŸ¼ì„ ì—°-ì›” í˜•íƒœë¡œ í†µì¼"""
    return pd.to_datetime(series).dt.to_period("M").astype(str)

# =========================================
# 3. ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤
# =========================================

# 3-1. ì¸ì› ë³€ë™ / ì…Â·í‡´ì‚¬ ì¸ì‚¬ì´íŠ¸
def analyze_headcount(df_change):
    text_blocks = []

    df = df_change.copy()
    df["ì›”"] = to_month_period(df["ì›”"])
    df = df.sort_values("ì›”")

    if len(df) < 3:
        return "ğŸ“Œ ì¸ì›ë³€ë™ ë°ì´í„°ê°€ 3ê°œì›” ë¯¸ë§Œì´ë¼, ì¶”ì„¸ ë¶„ì„ì€ ì–´ë µìŠµë‹ˆë‹¤. (ëª¨ë¥´ê² ìŠµë‹ˆë‹¤)"

    recent_df = df.tail(6).copy()
    recent_df_reset = recent_df.reset_index(drop=True)

    last3 = recent_df_reset.tail(3)
    prev3 = recent_df_reset.head(len(recent_df_reset) - 3)

    if len(prev3) == 0:
        prev3 = last3  # ë¹„êµ ë¶ˆê°€ ì‹œ ë™ì¼ ê¸°ê°„ìœ¼ë¡œ ì²˜ë¦¬ (ì¶”ì¸¡ì…ë‹ˆë‹¤)

    hire_last3 = last3["ì…ì‚¬ì"].sum()
    hire_prev3 = prev3["ì…ì‚¬ì"].sum()
    sep_last3 = last3["í‡´ì‚¬ì"].sum()
    sep_prev3 = prev3["í‡´ì‚¬ì"].sum()

    total_last = df["ì´ì›"].iloc[-1]
    total_first = df["ì´ì›"].iloc[0]
    total_change = total_last - total_first

    def pct_change(new, old):
        if old == 0:
            return np.nan
        return (new - old) / old * 100

    hire_chg = pct_change(hire_last3, hire_prev3)
    sep_chg = pct_change(sep_last3, sep_prev3)

    # 1) ì…ì‚¬ì ì¶”ì„¸ (í‘œí˜„ ë‹¤ì–‘í™”)
    hire_comment = f"ìµœê·¼ 3ê°œì›” ì…ì‚¬ìëŠ” ì´ **{hire_last3}ëª…**ì´ë©°, ì§ì „ 3ê°œì›” ëŒ€ë¹„ "
    if pd.isna(hire_chg):
        hire_comment += "ë¹„êµ ê°€ëŠ¥í•œ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í™•ì‹¤í•˜ì§€ ì•ŠìŒ)"
    elif hire_chg > 40:
        hire_comment += (
            f"**{hire_chg:.1f}% ê¸‰ì¦**í–ˆìŠµë‹ˆë‹¤. ê³µê²©ì ìœ¼ë¡œ ì¸ë ¥ì„ í™•ì¥í•˜ëŠ” êµ­ë©´ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif hire_chg > 20:
        hire_comment += (
            f"**{hire_chg:.1f}% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ì±„ìš© ê°•ë„ê°€ ì´ì „ë³´ë‹¤ í™•ì‹¤íˆ ë†’ì•„ì§„ ìƒíƒœì…ë‹ˆë‹¤."
        )
    elif hire_chg > 5:
        hire_comment += (
            f"**{hire_chg:.1f}% ì†Œí­ ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ì™„ë§Œí•˜ê²Œ ì¸ë ¥ì„ í™•ì¶©í•˜ëŠ” íë¦„ì…ë‹ˆë‹¤."
        )
    elif hire_chg < -40:
        hire_comment += (
            f"**{abs(hire_chg):.1f}% ê¸‰ê°**í–ˆìŠµë‹ˆë‹¤. ì±„ìš© ì¶•ì†Œ ë˜ëŠ” ì±„ìš© ì „ëµ ë³€í™”ê°€ ìˆì—ˆì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif hire_chg < -20:
        hire_comment += (
            f"**{abs(hire_chg):.1f}% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. ì‹ ê·œ ì¶©ì›ì´ ëˆˆì— ë„ê²Œ ì¤„ì–´ë“  ìƒíƒœì…ë‹ˆë‹¤."
        )
    elif hire_chg < -5:
        hire_comment += (
            f"**{abs(hire_chg):.1f}% ì†Œí­ ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. ë‹¹ì¥ì€ í° ë¦¬ìŠ¤í¬ëŠ” ì•„ë‹ˆì§€ë§Œ, "
            "ì±„ìš© íŒŒì´í”„ë¼ì¸ì„ ì ê²€í•´ ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        hire_comment += (
            f"{hire_chg:.1f}% ë³€ë™ìœ¼ë¡œ, í° ë³€í™” ì—†ì´ **ì•ˆì •ì ì¸ ì±„ìš© ìˆ˜ì¤€**ì´ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        )
    text_blocks.append("ğŸ”¹ **ì…ì‚¬ì ì¶”ì„¸ ì¸ì‚¬ì´íŠ¸**\n" + hire_comment)

    # 2) í‡´ì‚¬ì ì¶”ì„¸ (í‘œí˜„ ë‹¤ì–‘í™”)
    sep_comment = f"ìµœê·¼ 3ê°œì›” í‡´ì‚¬ìëŠ” ì´ **{sep_last3}ëª…**ì´ë©°, ì§ì „ 3ê°œì›” ëŒ€ë¹„ "
    if pd.isna(sep_chg):
        sep_comment += "ë¹„êµ ê°€ëŠ¥í•œ ê³¼ê±° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í™•ì‹¤í•˜ì§€ ì•ŠìŒ)"
    elif sep_chg > 40:
        sep_comment += (
            f"**{sep_chg:.1f}% ê¸‰ì¦**í–ˆìŠµë‹ˆë‹¤. ë‹¨ê¸°ê°„ì— ì´íƒˆì´ ëª°ë¦¬ë©´ì„œ, "
            "ì¡°ì§ ì•ˆì •ì„± ì¸¡ë©´ì—ì„œ ê°•í•œ ê²½ê³  ì‹ í˜¸ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif sep_chg > 20:
        sep_comment += (
            f"**{sep_chg:.1f}% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ì´íƒˆì´ ëˆˆì— ë„ê²Œ ë§ì•„ì§„ êµ¬ê°„ìœ¼ë¡œ, "
            "ì›ì¸ ë¶„ì„ê³¼ ì¡°ê¸° ëŒ€ì‘ì´ í•„ìš”í•œ ìƒíƒœì…ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif sep_chg > 5:
        sep_comment += (
            f"**{sep_chg:.1f}% ì†Œí­ ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ë‹¹ì¥ ì‹¬ê°í•œ ìˆ˜ì¤€ì€ ì•„ë‹ˆì§€ë§Œ, "
            "íŠ¹ì • ë¶€ì„œÂ·ì§ë¬´ì— í¸ì¤‘ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif sep_chg < -20:
        sep_comment += (
            f"**{abs(sep_chg):.1f}% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. ì´íƒˆì´ ëšœë ·í•˜ê²Œ ì¤„ì–´ë“  ì•ˆì • êµ¬ê°„ì…ë‹ˆë‹¤."
        )
    elif sep_chg < -5:
        sep_comment += (
            f"**{abs(sep_chg):.1f}% ì†Œí­ ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. ì´íƒˆ ê´€ë¦¬ê°€ ë¹„êµì  ì˜ ì´ë¤„ì§€ê³  ìˆëŠ” íë¦„ì…ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        sep_comment += (
            f"{sep_chg:.1f}% ë³€ë™ìœ¼ë¡œ, ì´íƒˆ ìˆ˜ì¤€ì€ **í¬ê²Œ í”ë“¤ë¦¼ ì—†ì´ ìœ ì§€**ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        )
    text_blocks.append("ğŸ”¹ **í‡´ì‚¬ì ì¶”ì„¸ ì¸ì‚¬ì´íŠ¸**\n" + sep_comment)

    # 3) ì´ì› ì¶”ì„¸ (ì¥ê¸°)
    if total_change > 0:
        total_comment = (
            f"ë¶„ì„ ê¸°ê°„ ì „ì²´ë¡œ ë³´ë©´ ì´ì›ì€ **+{total_change}ëª…** ì¦ê°€í–ˆìŠµë‹ˆë‹¤. "
            "ì¥ê¸°ì ìœ¼ë¡œ ì¡°ì§ì„ í‚¤ì›Œê°€ëŠ” ì„±ì¥ ì „ëµì´ ìœ ì§€ë˜ê³  ìˆëŠ” ëª¨ìŠµì…ë‹ˆë‹¤."
        )
    elif total_change < 0:
        total_comment = (
            f"ë¶„ì„ ê¸°ê°„ ì „ì²´ë¡œ ë³´ë©´ ì´ì›ì€ **{total_change}ëª…** ê°ì†Œí–ˆìŠµë‹ˆë‹¤. "
            "ì±„ìš© ì¶•ì†Œ, ìì—° ì´íƒˆ, ì„ íƒì  êµ¬ì¡°ì¡°ì • ë“±ì´ í•¨ê»˜ ì˜í–¥ì„ ì¤€ ê²°ê³¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        total_comment = (
            "ë¶„ì„ ê¸°ê°„ ë™ì•ˆ ì´ì›ì€ ê±°ì˜ ë³€ë™ì´ ì—†ì—ˆìŠµë‹ˆë‹¤. "
            "ì±„ìš©ê³¼ í‡´ì‚¬ê°€ ê±°ì˜ ê· í˜•ì„ ì´ë£¨ëŠ”, ì•ˆì •ì ì¸ ì¸ë ¥ ìœ ì§€ êµ¬ê°„ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
    text_blocks.append("ğŸ”¹ **ì´ì› ì¥ê¸° ì¶”ì„¸ ì¸ì‚¬ì´íŠ¸**\n" + total_comment)

    # 4) ì¢…í•© í‰ê°€
    net_last3 = hire_last3 - sep_last3
    if net_last3 > 0 and (not pd.isna(sep_chg) and sep_chg < 20):
        overall = (
            "ìµœê·¼ 3ê°œì›”ì€ **ìˆœì¦ê°€(ì…ì‚¬ > í‡´ì‚¬)** êµ¬ê°„ìœ¼ë¡œ, "
            "ë‹¨ê¸° ë¦¬ìŠ¤í¬ëŠ” ë‚®ê³  ì„±ì¥ì„ ì§€í–¥í•˜ëŠ” êµ­ë©´ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    elif net_last3 < 0 and (not pd.isna(sep_chg) and sep_chg > 20):
        overall = (
            "ìµœê·¼ 3ê°œì›”ì€ **ìˆœê°ì†Œ(í‡´ì‚¬ > ì…ì‚¬)** êµ¬ê°„ì´ë©°, "
            "í‡´ì‚¬ ì¦ê°€ê¹Œì§€ ê²¹ì³ **ì¡°ì§ ì•ˆì •ì„± ì¸¡ë©´ì—ì„œ ì£¼ì˜ ê¹Šì€ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•œ ì‹œê¸°**ì…ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        overall = (
            "ì…Â·í‡´ì‚¬ì™€ ì´ì› ëª¨ë‘ í° í­ì˜ ë³€í™”ëŠ” ì•„ë‹ˆì§€ë§Œ, "
            "ì„¸ë¶€ ë¶€ì„œÂ·ì§ë¬´ ë‹¨ìœ„ì—ì„œì˜ ë³€ë™ íŒ¨í„´ì„ í•¨ê»˜ ì‚´í´ë³´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    text_blocks.append("ğŸ”¹ **ì¢…í•© ì¸ì‚¬ì´íŠ¸**\n" + overall)

    return "\n\n".join(text_blocks)

# 3-2. ë¶€ì„œë³„ í‡´ì‚¬ ë¦¬ìŠ¤í¬ ë¶„ì„ (ì˜µì…˜ A: ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨ í˜¼í•© ìŠ¤ì½”ì–´)
def analyze_department_turnover(df_turnover, show_table=True):
    text_blocks = []

    df = df_turnover.copy()
    df = df.sort_values("ì—°ë„")

    years = sorted(df["ì—°ë„"].unique())
    if len(years) < 2:
        return "ğŸ“Œ ì „ë…„ ëŒ€ë¹„ ë¶„ì„ì„ í•  ìˆ˜ ìˆì„ ë§Œí¼ ì—°ë„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ëª¨ë¥´ê² ìŠµë‹ˆë‹¤)", None

    last_year = years[-1]   # ìµœì‹  ì—°ë„
    prev_year = years[-2]   # ì§ì „ ì—°ë„

    recent_df = df[df["ì—°ë„"] == last_year]
    prev_df = df[df["ì—°ë„"] == prev_year]

    dept_cols = [c for c in df.columns if c != "ì—°ë„"]

    # ì˜¬í•´ ì „ì²´ ë¶€ì„œ í‡´ì‚¬ììˆ˜ í‰ê·  (ì ˆëŒ€ ê·œëª¨ ê¸°ì¤€)
    total_this_year = []
    for col in dept_cols:
        total_this_year.append(recent_df[col].sum())
    overall_avg_this_year = np.mean(total_this_year) if len(total_this_year) > 0 else np.nan

    risk_rows = []
    for col in dept_cols:
        this_year_val = recent_df[col].sum()
        prev_year_val = prev_df[col].sum()

        # 1) ì „ë…„ ëŒ€ë¹„ ìŠ¤ì½”ì–´
        if prev_year_val == 0:
            yoy_score = np.nan
        else:
            yoy_score = this_year_val / prev_year_val

        # 2) ì ˆëŒ€ ê·œëª¨ ìŠ¤ì½”ì–´ (ì˜¬í•´ ì „ì²´ í‰ê·  ëŒ€ë¹„)
        if overall_avg_this_year == 0 or np.isnan(overall_avg_this_year):
            abs_score = np.nan
        else:
            abs_score = this_year_val / overall_avg_this_year

        # 3) ìµœì¢… ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ (í˜¼í•©)
        if np.isnan(yoy_score) and not np.isnan(abs_score):
            final_score = abs_score
        elif np.isnan(abs_score) and not np.isnan(yoy_score):
            final_score = yoy_score
        elif np.isnan(yoy_score) and np.isnan(abs_score):
            final_score = np.nan
        else:
            final_score = 0.5 * yoy_score + 0.5 * abs_score

        risk_rows.append((col, this_year_val, prev_year_val, yoy_score, abs_score, final_score))

    risk_df = pd.DataFrame(
        risk_rows,
        columns=[
            "ë¶€ì„œ",
            f"{last_year}ë…„_í‡´ì‚¬ììˆ˜",
            f"{prev_year}ë…„_í‡´ì‚¬ììˆ˜",
            "ì „ë…„ëŒ€ë¹„ìŠ¤ì½”ì–´",
            "ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´",
            "ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´"
        ]
    ).sort_values("ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´", ascending=False)

    # ê¸°ë³¸ ë“±ê¸‰ì€ Low
    risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] = "Low"

    # ìµœì¢… ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ê°€ 1.2 ì´ìƒì¸ ë¶€ì„œë“¤ ì¤‘ ìƒìœ„ 2ê°œë¥¼ Highë¡œ ì„¤ì •
    candidates = risk_df[risk_df["ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´"] >= 1.2].copy()
    top_high = candidates.head(2).index
    risk_df.loc[top_high, "ë¦¬ìŠ¤í¬ë“±ê¸‰"] = "High"

    # ë‚˜ë¨¸ì§€ ì¤‘ì—ì„œ 1.0 ì´ìƒ 1.2 ë¯¸ë§Œì€ Medium
    medium_mask = (risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] == "Low") & (risk_df["ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´"] >= 1.0)
    risk_df.loc[medium_mask, "ë¦¬ìŠ¤í¬ë“±ê¸‰"] = "Medium"

    # í‘œ í‘œì‹œ ì—¬ë¶€
    if show_table:
        st.dataframe(
            risk_df.style.format(
                {
                    f"{last_year}ë…„_í‡´ì‚¬ììˆ˜": "{:.0f}",
                    f"{prev_year}ë…„_í‡´ì‚¬ììˆ˜": "{:.0f}",
                    "ì „ë…„ëŒ€ë¹„ìŠ¤ì½”ì–´": "{:.2f}",
                    "ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´": "{:.2f}",
                    "ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´": "{:.2f}",
                }
            ),
            use_container_width=True
        )

    # ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸
    high_risk = risk_df[risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] == "High"]
    medium_risk = risk_df[risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] == "Medium"]

    if not high_risk.empty:
        dept_list = ", ".join(
            f"{row.ë¶€ì„œ}íŒ€("
            f"{last_year}ë…„ {row[f'{last_year}ë…„_í‡´ì‚¬ììˆ˜']:.0f}ëª…, "
            f"{prev_year}ë…„ ëŒ€ë¹„ {row['ì „ë…„ëŒ€ë¹„ìŠ¤ì½”ì–´']:.2f}ë°°, "
            f"ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´ {row['ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´']:.2f}, "
            f"ìµœì¢… {row['ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´']:.2f})"
            for _, row in high_risk.iterrows()
        )
        text_blocks.append(
            f"ğŸ”´ **High Risk ë¶€ì„œ ì¸ì‚¬ì´íŠ¸ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
            f"{dept_list} ì—ì„œ ì „ë…„ ëŒ€ë¹„ ì¦ê°€ í­ê³¼ ì ˆëŒ€ í‡´ì‚¬ ê·œëª¨ê°€ ëª¨ë‘ ë†’ì€ í¸ì…ë‹ˆë‹¤. "
            f"ì¡°ì§ë¬¸í™”, ë¦¬ë”ì‹­, ì—­í• ì í•©ì„±, ë³´ìƒ ë“± ì›ì¸ ì§„ë‹¨ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        text_blocks.append(
            "ğŸ”´ **High Risk ë¶€ì„œ ì¸ì‚¬ì´íŠ¸ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
            "í˜„ì¬ ê¸°ì¤€ìœ¼ë¡œ ì „ë…„ ëŒ€ë¹„ ì¦ê°€ í­ê³¼ ì ˆëŒ€ ê·œëª¨ë¥¼ í•¨ê»˜ ë³´ì•˜ì„ ë•Œ, "
            "ê°•í•˜ê²Œ ê²½ê³ ê°€ í•„ìš”í•œ ë¶€ì„œëŠ” ì—†ìŠµë‹ˆë‹¤."
        )

    if not medium_risk.empty:
        dept_list = ", ".join(
            f"{row.ë¶€ì„œ}íŒ€("
            f"{last_year}ë…„ {row[f'{last_year}ë…„_í‡´ì‚¬ììˆ˜']:.0f}ëª…, "
            f"{prev_year}ë…„ ëŒ€ë¹„ {row['ì „ë…„ëŒ€ë¹„ìŠ¤ì½”ì–´']:.2f}ë°°, "
            f"ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´ {row['ì ˆëŒ€ê·œëª¨ìŠ¤ì½”ì–´']:.2f}, "
            f"ìµœì¢… {row['ìµœì¢…ë¦¬ìŠ¤í¬ìŠ¤ì½”ì–´']:.2f})"
            for _, row in medium_risk.iterrows()
        )
        text_blocks.append(
            f"ğŸŸ  **Medium Risk ë¶€ì„œ ì¸ì‚¬ì´íŠ¸ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
            f"{dept_list} ìˆ˜ì¤€ìœ¼ë¡œ, ì•ìœ¼ë¡œì˜ ì¶”ì´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë©´ì„œ "
            f"í‡´ì‚¬ ì‚¬ìœ ì™€ íŒ¨í„´ì„ ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        text_blocks.append(
            "ğŸŸ  **Medium Risk ë¶€ì„œ ì¸ì‚¬ì´íŠ¸ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
            "ì „ë…„ ëŒ€ë¹„ ì¦ê°€ í­ê³¼ ì ˆëŒ€ ê·œëª¨ë¥¼ í•¨ê»˜ ë³´ì•˜ì„ ë•Œ, "
            "ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì£¼ì˜ê°€ í•„ìš”í•œ ë¶€ì„œëŠ” ì•„ì§ ëšœë ·í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

    low_count = (risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] == "Low").sum()
    text_blocks.append(
        f"ğŸŸ¢ **Low Risk ë¶€ì„œ ì¸ì‚¬ì´íŠ¸**\n"
        f"ì „ë…„ê³¼ ìœ ì‚¬í•˜ê±°ë‚˜ ë” ë‚®ì€ ìˆ˜ì¤€(ë˜ëŠ” ê·œëª¨ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ ìˆ˜ì¤€)ì˜ ë¶€ì„œëŠ” ì´ **{low_count}ê°œ**ì…ë‹ˆë‹¤."
    )

    return "\n\n".join(text_blocks), risk_df

# 3-3. ì”ì¡´ìœ¨ ë¶„ì„ (ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ ê´€ì , í‘œ í‘œì‹œ ì˜µì…˜)
def analyze_retention(df_retention, show_table=True):
    text_blocks = []

    df = df_retention.copy()

    pivot_12 = df[df["ê²½ê³¼ê°œì›”"] == 12].copy()
    if pivot_12.empty:
        text_blocks.append("ğŸ“Œ 12ê°œì›” ì”ì¡´ìœ¨ ë°ì´í„°ê°€ ì—†ì–´ ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ ë¹„êµëŠ” ì–´ë µìŠµë‹ˆë‹¤. (ëª¨ë¥´ê² ìŠµë‹ˆë‹¤)")
    else:
        worst = pivot_12.sort_values("ì”ì¡´ìœ¨").iloc[0]
        best = pivot_12.sort_values("ì”ì¡´ìœ¨", ascending=False).iloc[0]
        text_blocks.append(
            "ğŸ”¹ **12ê°œì›” ì”ì¡´ìœ¨ ê¸°ì¤€ ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ ë¹„êµ ì¸ì‚¬ì´íŠ¸**\n"
            f"- ìµœì € ì”ì¡´ìœ¨: **{int(worst['ì…ì‚¬ì—°ë„'])}ë…„ ì…ì‚¬ ê·¸ë£¹** ({worst['ì”ì¡´ìœ¨']:.1f}%)\n"
            f"- ìµœê³  ì”ì¡´ìœ¨: **{int(best['ì…ì‚¬ì—°ë„'])}ë…„ ì…ì‚¬ ê·¸ë£¹** ({best['ì”ì¡´ìœ¨']:.1f}%)\n"
            "â†’ íŠ¹ì • ì…ì‚¬ì—°ë„ ê·¸ë£¹ì—ì„œ ì˜¨ë³´ë”©, ë°°ì¹˜, ì¡°ì§ì í•©ì„± ë“± ê²½í—˜ì˜ ì§ˆì´ ë‹¬ëì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )

    drops = []
    for year, g in df.groupby("ì…ì‚¬ì—°ë„"):
        g = g.sort_values("ê²½ê³¼ê°œì›”")
        g["change"] = g["ì”ì¡´ìœ¨"].diff()
        big_drop = g[g["change"] <= -10]
        for _, row in big_drop.iterrows():
            drops.append(
                (
                    year,
                    int(row["ê²½ê³¼ê°œì›”"]),
                    row["change"]
                )
            )

    if drops:
        drops_df = pd.DataFrame(drops, columns=["ì…ì‚¬ì—°ë„", "ê²½ê³¼ê°œì›”", "ë³€í™”ëŸ‰"])
        drops_df = drops_df.sort_values("ë³€í™”ëŸ‰")

        if show_table:
            st.dataframe(
    drops_df.reset_index(drop=True),
    use_container_width=True
)


        example = drops_df.iloc[0]
        text_blocks.append(
            "ğŸ”¹ **ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ì˜ ì”ì¡´ìœ¨ ê¸‰ë½ êµ¬ê°„ ì¸ì‚¬ì´íŠ¸**\n"
            f"- ì˜ˆ: {int(example['ì…ì‚¬ì—°ë„'])}ë…„ ì…ì‚¬ ê·¸ë£¹ì˜ "
            f"{int(example['ê²½ê³¼ê°œì›”'])}ê°œì›” ì‹œì ì—ì„œ ì”ì¡´ìœ¨ì´ **{example['ë³€í™”ëŸ‰']:.1f}p** ê¸‰ë½í–ˆìŠµë‹ˆë‹¤.\n"
            "â†’ í•´ë‹¹ ì‹œì  ì „í›„ì˜ í‰ê°€, ì¡°ì§ê°œí¸, ë¦¬ë” ë³€ê²½, ë³´ìƒ ì´ë²¤íŠ¸ ë“±ì„ í•¨ê»˜ ê²€í† í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
        )
    else:
        text_blocks.append(
            "ğŸ”¹ **ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ì˜ ì”ì¡´ìœ¨ ê¸‰ë½ êµ¬ê°„ ì¸ì‚¬ì´íŠ¸**\n"
            "ì—°ì† êµ¬ê°„ì—ì„œ -10%p ì´ìƒ ê¸‰ë½í•œ íŒ¨í„´ì€ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

    return "\n\n".join(text_blocks)

# 3-4. ì…ì‚¬ì—°ë„ë³„ ì”ì¡´ìœ¨ ë¼ì¸ ê·¸ë˜í”„ìš© ë°ì´í„°
def make_retention_line_data(df_retention):
    df = df_retention.copy()
    line_df = df.pivot_table(
        index="ê²½ê³¼ê°œì›”",
        columns="ì…ì‚¬ì—°ë„",
        values="ì”ì¡´ìœ¨",
        aggfunc="mean"
    ).sort_index()
    return line_df

# 3-5. ì•¡ì…˜ í¬ì¸íŠ¸ ìƒì„±
def generate_action_points(headcount_comment, risk_df, retention_comment):
    points = []

    if risk_df is not None:
        high_risk = risk_df[risk_df["ë¦¬ìŠ¤í¬ë“±ê¸‰"] == "High"]
        if not high_risk.empty:
            dept_names = ", ".join(high_risk["ë¶€ì„œ"].tolist())
            points.append(
                f"1) **High Risk ë¶€ì„œ ì§‘ì¤‘ ì§„ë‹¨ ì œì•ˆ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
                f"- ëŒ€ìƒ: {dept_names}\n"
                f"- ì•¡ì…˜: í‡´ì‚¬ì ì¸í„°ë·°, ì¡°ì§ë¬¸í™”/ë¦¬ë”ì‹­ ì§„ë‹¨, ì—­í• Â·ì„±ê³¼ ê¸°ëŒ€ì¹˜ ëª…í™•í™” ì›Œí¬ìˆ ë“±ì„ ìš°ì„  ê²€í† í•©ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
            )
        else:
            points.append(
                "1) **High Risk ë¶€ì„œ ì§‘ì¤‘ ì§„ë‹¨ ì œì•ˆ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)**\n"
                "- í˜„ì¬ ê¸°ì¤€ìœ¼ë¡œ High Riskì— í•´ë‹¹í•˜ëŠ” ë¶€ì„œëŠ” ì—†ì§€ë§Œ, "
                "í‡´ì‚¬ ì¦ê°€ ì‹ í˜¸ê°€ ë‚˜íƒ€ë‚  ê²½ìš° ì‹ ì†íˆ ì§‘ì¤‘ ì§„ë‹¨ì„ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
            )

    points.append(
        "2) **ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ ì”ì¡´ìœ¨ ê²©ì°¨ ê´€ë¦¬ ì œì•ˆ**\n"
        "- ì”ì¡´ìœ¨ì´ ë‚®ì€ ì…ì‚¬ì—°ë„ ê·¸ë£¹ì„ ì¤‘ì‹¬ìœ¼ë¡œ, ì´ˆê¸° ì˜¨ë³´ë”©/ë°°ì¹˜/í”¼ë“œë°± êµ¬ì¡°ë¥¼ ì ê²€í•˜ê³  "
        "ë™ì¼ ì‹œê¸°ì— ì…ì‚¬í•œ êµ¬ì„±ì›ë“¤ì˜ ê³µí†µ ê²½í—˜ì„ ì¸í„°ë·°ë¡œ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
    )

    points.append(
        "3) **ì”ì¡´ìœ¨ ê¸‰ë½ ì‹œì  ì¬ì ê²€ ì œì•ˆ**\n"
        "- ì”ì¡´ìœ¨ì´ íŠ¹ì • ì‹œì  ì´í›„ í¬ê²Œ ë–¨ì–´ì§€ëŠ” ê²½ìš°, ê·¸ ì „í›„ë¡œ ìˆì—ˆë˜ í‰ê°€, ì¡°ì§ê°œí¸, ë¦¬ë” ë³€ê²½, "
        "ë³´ìƒ/ì„±ê³¼ ì œë„ ë³€ê²½ ë“± ì¡°ì§ ì´ë²¤íŠ¸ë¥¼ í•¨ê»˜ í™•ì¸í•˜ê³ , ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë° ì œë„ ë³´ì™„ ë°©ì•ˆì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
    )

    points.append(
        "4) **ì…Â·í‡´ì‚¬ ë° ì´ì› ì¶”ì„¸ ê¸°ë°˜ ì±„ìš©/ìš´ì˜ ì „ëµ ì¡°ì • ì œì•ˆ**\n"
        "- í‡´ì‚¬ ì¦ê°€ê°€ ê°ì§€ë˜ëŠ” ì‹œì ì—ëŠ” ë‹¨ê¸°ì ì¸ ì¶©ì› ê³„íšë¿ ì•„ë‹ˆë¼, "
        "ì´íƒˆ ì‚¬ìœ ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘Â·ë¶„ì„í•˜ì—¬ ì¤‘ì¥ê¸°ì ì¸ êµ¬ì¡° ê°œì„  ë°©í–¥ê¹Œì§€ í•¨ê»˜ ê²€í† í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. (ì¶”ì¸¡ì…ë‹ˆë‹¤)"
    )

    return "\n\n".join(points)

# =========================================
# 4. ë©”ì¸ í™”ë©´ êµ¬ì„±
# =========================================
try:
    df_change, df_turnover, df_retention, df_tenure = load_data()
    data_loaded = True
except FileNotFoundError:
    st.error("`company_hr_data.xlsx` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    data_loaded = False
except Exception as e:
    st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    data_loaded = False

if not data_loaded:
    st.stop()

# ğŸ‘‰ ì‚¬ì´ë“œë°”ëŠ” í˜ì´ì§€ ì„ íƒë§Œ ê°„ê²°í•˜ê²Œ
menu = st.sidebar.radio(
    "í˜ì´ì§€ ì„ íƒ",
    ["1. ì¡°ì§ í˜„í™© ìŠ¤ëƒ…ìƒ·", "2. ë¦¬í…ì…˜ ë¶„ì„", "3. ì•¡ì…˜ í¬ì¸íŠ¸"]
)

# -------------------------------------
# í˜ì´ì§€ 1: ì¡°ì§ í˜„í™© ìŠ¤ëƒ…ìƒ·
# -------------------------------------
if menu.startswith("1"):
    st.subheader("ğŸ“ í˜ì´ì§€ 1 â€” ì¡°ì§ í˜„í™© ìŠ¤ëƒ…ìƒ·")

    df_change_view = df_change.copy()
    df_change_view["ì›”"] = to_month_period(df_change_view["ì›”"])
    df_change_view = df_change_view.sort_values("ì›”")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**ì›”ë³„ ì…Â·í‡´ì‚¬ ì¶”ì´**")
        st.line_chart(
            df_change_view.set_index("ì›”")[["ì…ì‚¬ì", "í‡´ì‚¬ì"]]
        )

    with col2:
        st.markdown("**ì›”ë³„ ì´ì› ì¶”ì„¸**")
        st.line_chart(
            df_change_view.set_index("ì›”")[["ì´ì›"]]
        )

    st.markdown("---")
    st.markdown("### ğŸ§  ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸")

    headcount_comment = analyze_headcount(df_change)
    st.markdown(headcount_comment)

# -------------------------------------
# í˜ì´ì§€ 2: ë¦¬í…ì…˜ ë¶„ì„
# -------------------------------------
elif menu.startswith("2"):
    st.subheader("ğŸ“ í˜ì´ì§€ 2 â€” ë¦¬í…ì…˜ ë¶„ì„")

    st.markdown("#### ğŸ”¥ ë¶€ì„œë³„ í‡´ì‚¬ì ìˆ˜ (ì—°ë„Ã—ë¶€ì„œ)")
    turnover_melt = df_turnover.melt(id_vars=["ì—°ë„"], var_name="ë¶€ì„œ", value_name="í‡´ì‚¬ììˆ˜")
    turnover_pivot = turnover_melt.pivot(index="ì—°ë„", columns="ë¶€ì„œ", values="í‡´ì‚¬ììˆ˜")
    st.dataframe(turnover_pivot, use_container_width=True)

    st.markdown("---")
    st.markdown("### ğŸ§  ë¶€ì„œë³„ ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸ (ì „ë…„ ëŒ€ë¹„ + ì ˆëŒ€ ê·œëª¨)")
    dept_comment, risk_df = analyze_department_turnover(df_turnover, show_table=True)
    st.markdown(dept_comment)

    st.markdown("---")
    st.markdown("### ğŸ“ˆ ì…ì‚¬ì—°ë„ë³„ ì”ì¡´ìœ¨ ì¶”ì´ (ê·¸ë£¹ë³„ ë¼ì¸ ê·¸ë˜í”„)")
    retention_line_df = make_retention_line_data(df_retention)
    st.line_chart(retention_line_df)

    st.markdown("---")
    st.markdown("### ğŸ§  ì”ì¡´ìœ¨ ì¸ì‚¬ì´íŠ¸ ì½”ë©˜íŠ¸ (ì…ì‚¬ì—°ë„ë³„ ê·¸ë£¹ ê´€ì )")
    retention_comment = analyze_retention(df_retention, show_table=True)
    st.markdown(retention_comment)

# -------------------------------------
# í˜ì´ì§€ 3: ì•¡ì…˜ í¬ì¸íŠ¸
# -------------------------------------
elif menu.startswith("3"):
    st.subheader("ğŸ“ í˜ì´ì§€ 3 â€” ì•¡ì…˜ í¬ì¸íŠ¸")

    headcount_comment = analyze_headcount(df_change)
    dept_comment, risk_df = analyze_department_turnover(df_turnover, show_table=False)
    retention_comment = analyze_retention(df_retention, show_table=False)

    st.markdown("### ğŸ§  ìš”ì•½ ì¸ì‚¬ì´íŠ¸")
    if "ğŸ”¹ **ì¢…í•© ì¸ì‚¬ì´íŠ¸**" in headcount_comment:
        summary_part = headcount_comment.split("ğŸ”¹ **ì¢…í•© ì¸ì‚¬ì´íŠ¸**")[-1]
        st.markdown("**ì¡°ì§ í˜„í™© ì¢…í•© ì¸ì‚¬ì´íŠ¸**" + summary_part)
    else:
        st.markdown(headcount_comment)

    st.markdown("---")
    st.markdown("### âœ… HR ì•¡ì…˜ í¬ì¸íŠ¸ ì œì•ˆ")

    action_points = generate_action_points(
        headcount_comment, risk_df, retention_comment
    )
    st.markdown(action_points)



